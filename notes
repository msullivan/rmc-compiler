The general intuition is that pushes become syncs; visibility edges
become lwsyncs; and execution edges become either control-isyncs, or
data or address dependencies.  There are some subtleties though.
Ignoring read-modify-writes, the algorithm is as follows:

1. Take the transitive closure of the visibility edges, and take the
    transitive closure of the execution edges.
2. Discard any edges involving a nop.
3. For all triples of the form i -vo-> push -xo/vo-> i', create a push
    edge i -push-> i'.  (These exist in the algorithm only, not in the
    theory.)
4. Discard any edges involving a push.
5. Insert synchronization into the code such that:

    a. Every push edge is cut by a sync.
    b. Every W->W and R->W visibility edge is cut by a sync or lwsync.
    c. Every R->R edge is cut by a sync, lwsync,
       control-isync, or data/address dependency.
    d. Every R->W and execution edge is cut by a sync, lwsync,
       control-isync, data/address dependency, or control dependency.

    Doing so is interesting, particularly when edges cross from one
    basic block to another.

    Also, the execution stuff is a good deal trickier than that
    because of edges across loops. (And there are /always/ edges
    across loops, because the function will get called again!)

    Note that:

    a. R->R visibility edges have no more force than execution (other
       than transitive implications).
    b. W->R visibility and execution edges, and W->W execution edges,
       are discarded (after transitive closure).
    c. Pushes without both a visibility predecessor and a
       visibility/execution successor are discarded.


--
pre and post edges we will just add the stuff and then try to notice it.

honestly maybe that's what we should do for push also? although, won't
actually be hard to do push right, but maybe not worth the state space
blowup.

Should be a little careful because probably a common idiom will be:
  L(push, PUSH); VEDGE(pre, push); XEDGE(push, post);
and we should just generate a single sync in place and not do dumb things.

It will be common because I'll probably write a macro for it, so...

Will actually need special handling of pre/push to posts even just for
correctness!

--
I sort of dislike inserting all these barriers so early. I feel like
it might inhibit llvm more than we want.
--

But since we *do* insert all the barriers early, we actually can
implement pre and post by making dummy actions immediately before and
after actions with pre/post constraints. The only tricky thing is that
we need to make sure we don't try any funny business with dependencies
for xo edges.


------------------------------------------------------
Things about the paper:
  -- we need pushes for two threads writing to locations to get ordering:
     maybe we should require co+vo to be acyclic? is this important
  -- ISA2+lwsync+data+addr: our semantics don't allow us to generate this
      code and be correct; vo+xo+xo would allow the forbidden behavior;
      vo+vo+xo works, as does push+xo+xo;
      push+xo+xo is maaaybe what we want on ARM, but vo+vo+xo is
      definitely better on x86


--------------------------------------------

I think we are going to want to be able to adjust where labels get
"bound": that is, relative to loops, the function call, etc. This
seems important for doing consume style stuff. The thing that matches
the theory would be to handle it at the label declaration, but it
seems cleaner for code implementation to do it when specifying edges.

We *definitely* want to be able to bind inside a function. Loops more
complicated. What about gotos, etc.

Actually maybe not definitely. If rcu_read_unlock() has a barrier then
maybe we don't give a shit anymore.

*** Idea: allow explicitly specifying a binding location for a
label. That binding location then needs to dominate all occurances of
the label as well as anything with edges to/from that label. Then,
when looking at paths, we can ignore paths that go through the binding
site, I think. Not totally sure how to properly handle differing
binding sites between src/dst (technically they will probably always
differ, even if trivially...): maybe ignore the least common ancestor
dominator.

Probably also want a way to specify binding something at the "most
narrow possible binding" (least common dominator?).



--- How elaborate of real dependencies do we want to try to preserve?
And how do we preserve them?  Detecting and preserving straightforward
deps should be eaaaaasy.

We probably need to be able to handle linux RCU list style things,
which means handling bitcasts and GEPs.

*** We are definitely definitely going to need a notion of path dependence
for detecting dependency. A super common example of RCU is searching a
linked list, so...
* I should run some benchmarks to see how much faster it is with RCU.


-----

** Combining isync and depedencies might actually be quite profitable,
since all addresses need to be resolved, right?


----

DONE *** We need to adjust our notion of cost to take loops into account!
We will basically preferentially put things into loops instead of
taking them out, which is totally backwards.  Dunno if it should be
part of capacity or a seperate score.  Maybe increase the cost by a
factor of 4^n where n is the loop nesting count?  (4 because a loop
will probably have 1/2 the capacity of its parent; 4^n makes a loop
have twice the cost of its parent).
